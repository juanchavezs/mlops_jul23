{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Obtener la ruta absoluta del directorio actual\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Obtener la ruta absoluta del directorio padre\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Agregar el directorio padre a sys.path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.preprocess_data import DataPreprocessor\n",
    "data_transformer = DataPreprocessor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler # Data preprocessing\n",
    "\n",
    "\n",
    "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "  \n",
    "    def transform(self, X):\n",
    "        df_transformed = self.feature_generation(X)\n",
    "        #df_transformed = self.scaling_func(df_transformed)\n",
    "        return df_transformed\n",
    "\n",
    "    def preprocess_input(data):\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            return data\n",
    "        elif isinstance(data, dict):\n",
    "            df = pd.DataFrame([data])\n",
    "            return df\n",
    "        else:\n",
    "            raise ValueError(\"Los datos proporcionados no son compatibles.\")\n",
    "    \n",
    "    def feature_generation(self,data: pd.DataFrame) -> pd.DataFrame:        \n",
    "\n",
    "        # Calculate client age\n",
    "        data['Age'] = 2023 - data['Year_Birth']\n",
    "        \n",
    "        # Calculate number of years since customer registration\n",
    "        registration_year = pd.to_datetime(data['Dt_Customer'], format='%d-%m-%Y').apply(lambda x: x.year)\n",
    "        current_year = datetime.now().year\n",
    "        data['Years_Since_Registration'] = current_year - registration_year \n",
    "\n",
    "        # Encode Education\n",
    "        data[\"Education\"] = data[\"Education\"].replace({\"Basic\": 0, \"Graduation\": 1, \"2n Cycle\": 2, \"Master\": 2, \"PhD\": 3})\n",
    "        \n",
    "        # Calculate total amount spent on products\n",
    "        mnt_cols = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "        data['Sum_Mnt'] = data[mnt_cols].sum(axis=1)\n",
    "        \n",
    "        # Calculate number of companies in which the client accepted the offer\n",
    "        accepted_cmp_cols = ['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response']\n",
    "        data['Num_Accepted_Cmp'] = data[accepted_cmp_cols].sum(axis=1)\n",
    "\n",
    "        # Calculate total number of purchases\n",
    "        total_purchases = ['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']\n",
    "        data['Num_Total_Purchases'] = data[total_purchases].sum(axis=1)\n",
    "\n",
    "        # Drop missing values and unnecessary columns\n",
    "        data.dropna(inplace=True)\n",
    "        data.drop(['Year_Birth', 'Z_CostContact', 'Z_Revenue', 'Dt_Customer', 'Marital_Status'], axis=1, inplace=True)\n",
    "    \n",
    "        # Apply one-hot encoding for remaining categorical features\n",
    "        data = pd.get_dummies(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def scaling_func(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        mms = MinMaxScaler()\n",
    "        return pd.DataFrame(data=mms.fit_transform(data), columns=data.columns)\n",
    "\n",
    "    models_dir = '../models/'\n",
    "\n",
    "    # def load_kmeans_model(self,n_clusters):\n",
    "    #     return joblib.load(model_filename)\n",
    "\n",
    "def predict_clusters(data,n_clusters):\n",
    "    kmeans_model = joblib.load(f\"../models/kmeans_{n_clusters}_clusters_model.pkl\")\n",
    "    return kmeans_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {\n",
    "    \"ID\": 1,\n",
    "    \"Education\": \"Graduation\",\n",
    "    \"Year_Birth\": 1957,\n",
    "    \"Marital_Status\": \"Single\",\n",
    "    \"Income\": 2103,\n",
    "    \"Kidhome\": 0,\n",
    "    \"Teenhome\": 0,\n",
    "    \"Dt_Customer\": \"04-09-2012\",\n",
    "    \"Recency\": 50,\n",
    "    \"MntWines\": 22,\n",
    "    \"MntFruits\": 88,\n",
    "    \"MntMeatProducts\": 546,\n",
    "    \"MntFishProducts\": 172,\n",
    "    \"MntSweetProducts\": 88,\n",
    "    \"MntGoldProds\": 88,\n",
    "    \"NumDealsPurchases\": 3,\n",
    "    \"NumWebPurchases\": 8,\n",
    "    \"NumCatalogPurchases\": 10,\n",
    "    \"NumStorePurchases\": 4,\n",
    "    \"NumWebVisitsMonth\": 7,\n",
    "    \"AcceptedCmp3\": 0,\n",
    "    \"AcceptedCmp4\": 0,\n",
    "    \"AcceptedCmp5\": 0,    \n",
    "    \"AcceptedCmp1\": 0,\n",
    "    \"AcceptedCmp2\": 0,\n",
    "    \"Complain\": 0,\n",
    "    \"Z_CostContact\": 3,\n",
    "    \"Z_Revenue\": 11,\n",
    "    \"Response\": 1\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([json_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataPreprocessor.feature_generation() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_transform \u001b[39m=\u001b[39m data_transformer\u001b[39m.\u001b[39;49mfeature_generation(\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m,df)\n\u001b[0;32m      2\u001b[0m predict_clusters(data\u001b[39m=\u001b[39mdf_transform,n_clusters\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: DataPreprocessor.feature_generation() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "df_transform = data_transformer.feature_generation('/',df)\n",
    "predict_clusters(data=df_transform,n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "if __name__ == \"__main|a__\":\n",
    "    LoadAndPredict = LoadAndPredict()\n",
    "\n",
    "      # Load new data for prediction\n",
    "    df = pd.read_csv(\"../data/retrieved_data.csv\")  # Replace with your new data file\n",
    "\n",
    "    # Prepare data\n",
    "    df = DataPreprocessor.feature_generation('/',df)\n",
    "    df_transform = DataPreprocessor.scaling_func('/',df)\n",
    " \n",
    "    # Predict clusters for the new data\n",
    "    df['Predicted_Cluster'] = LoadAndPredict.predict_clusters(df_transform)\n",
    "     \n",
    "    # Save preprocessed data with predictions to a new CSV\n",
    "    df.to_csv(\"data_with_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
